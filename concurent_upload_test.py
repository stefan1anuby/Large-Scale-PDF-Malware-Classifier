import requests
import os
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import statistics
import numpy as np

def upload_file(api_url, file_path, token=None):
    
    with open(file_path, 'rb') as file:
        headers = {'Authorization': token} if token else {}
        file = {'file': (file_path, file)}
        
        start_time = time.time()  # Start timing here
        response = requests.post(api_url, files=file, headers=headers)
        end_time = time.time()  # End timing here
    
    duration = end_time - start_time  # Calculate duration
    
    return duration  # For statistical analysis, we only need the duration

# Example usage parameters
api_url = 'http://localhost:8082/upload'  # Replace with the actual API URL
directory_path = 'D:\\PDFs licenta\\test_clean'
token = 'YourTokenHere'  # Replace with your actual token, if needed
file_paths = [os.path.join(directory_path, file_name) for file_name in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, file_name))]

# List to store durations of each request
durations = []

workers_count = 100
# Create a ThreadPoolExecutor
with ThreadPoolExecutor(workers_count) as executor:
    # Submit tasks to the executor
    futures = [executor.submit(upload_file, api_url, file_paths[i], token) for i in range(workers_count)]
    
    # Wait for the futures to complete and gather durations
    for future in as_completed(futures):
        duration = future.result()
        durations.append(duration)
        print(f"Request completed in {duration:.2f} seconds.")

# Calculate statistical metrics
mean_duration = statistics.mean(durations)
std_deviation = statistics.stdev(durations)
percentile_99 = np.percentile(durations, 99)  # 99th percentile

print(f"\nMean request time: {mean_duration:.2f} seconds")
print(f"Standard deviation of request time: {std_deviation:.2f} seconds")
print(f"99th percentile of request time: {percentile_99:.2f} seconds")